
\chapter{Introduction}
	{\huge \itshape L}e but de notre travail est identifier et décrire les besoins en termes de Recherche de Filtres de Bloom \& Application à la recherche par mots clés. En effet, une fois qu'on tape un mot ou une chaîne de mots, l’application cherche dans la base de données une liste des documents qui contient les descriptions correspondantes à ces mots clés.
	
	Dans la base de données qui contient des grosses masses de données, les index sont basés sur les descriptions des documents. Chaque mot est une clé, chaque clé fait référence à une liste des documents contenant ce mot dans sa description(liste inversée). Contrairement à une liste normale, le mot clé est le nom du document et il contient la liste des mots qui se trouvent dans la description de ce document.
	
	Par exemple, pour un document : «PSAR : projet pour les étudiants de M1», normalement le mot clé est « PSAR » avec comme description « projet pour les étudiants de M1 », mais dans cette liste, les mots clés sont : PSAR, projet, étudiants et M1. Chaque mot clé est un index sur une liste de documents de notre base de données qui contiennent ce mot dans leur description.
	
	Dans la réalisation, on utilise les tables de hachage distribuées (DHT) pour stocker les listes inversées. L'avantage d'utilisation de ces tables est que la complexité est égale à $ \theta ${\em (1)} car on trouve directement l'élément que l'on recherche. La statégie de distribution des listes inversées la plus utilisée est appelée partitionnement vertical qui consiste à associer à chaque terme une clé qui désigne la paire qui stocke la liste inversée associée à ce terme. Une fois que la recherche lancée, le système cherche pour chaque mot saisi dans cet ensemble la liste des documents qui les contiennent, et puis fait l'intersection des listes inversées retrouvées. 

	Dans les systèmes pair-à-pair (P2P), chaque n{\oe}ud contient un ou plusieurs mots clés, une fois qu'un mot est cherché, le système va demander le n{\oe}ud où se trouve ces mots clés la liste des documents qui le contient. Le problème est que si l'on cherche un ensemble de mots, il doit obligatoirement envoyer plusieurs requêtes à plusieurs n{\oe}uds pour récupérer les listes des documents et faire l'intersection. Si on a un grand nombre de machines qui cherchent une quantité importante de mots clés, le système sera saturé. Et aussi, le problème se pose sur un ou quelques n{\oe}uds précises, et les autres sont libres dans la plupart de temps. 
	
	Donc, le coût de la recherche est d'autant plus élevé que la requête est précise et le déséquilibrage de charges des noeuds d'indexation du fait de la non-uniformité de la popularité des termes, ce sont des problèmes qu'on va rechercher la solution dans ce projet.
	
	